{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import asyncio\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from loguru import logger\n",
    "from glob import glob\n",
    "\n",
    "from mistral_fine_tuning.levels import KnowledgeGraph, extract_graph\n",
    "from mistral_fine_tuning.keywords import Topics, extract_keywords\n",
    "from mistral_fine_tuning.refine import Refinement, Quality, Rewrite, refine_joke, rewrite_joke\n",
    "from mistral_fine_tuning.utils import read_fine_tuning_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../data/interim/jokes'\n",
    "jsonl_files = glob(os.path.join(folder_path, '*.jsonl'))\n",
    "all_corrected_transcripts = []\n",
    "\n",
    "for file in jsonl_files:\n",
    "    with open(file, 'r', encoding='latin-1') as f:\n",
    "        for line in f:\n",
    "            data = json.loads(line)\n",
    "            all_corrected_transcripts.append(data['corrected_transcript'])\n",
    "\n",
    "df = pd.DataFrame(all_corrected_transcripts, columns=['text'])\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# add word count column\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of word count\n",
    "df['word_count'].hist(bins=100, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the top 5% and then filter word_count > 10 and \n",
    "df = df[df['word_count'] < df['word_count'].quantile(0.95)]\n",
    "df = df[df['word_count'] > 10]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# histogram of word count\n",
    "df['word_count'].hist(bins=25, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Levels of Intentionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def levels():\n",
    "    dataset = df['text'].tolist()\n",
    "    sem = asyncio.Semaphore(3)\n",
    "\n",
    "    async def rate_limited_extract_graph(text: str) -> KnowledgeGraph:\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await extract_graph(text, \"es\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing text: {text}\")\n",
    "                logger.error(e)\n",
    "                return None\n",
    "    \n",
    "    def safe_model_dump(graph):\n",
    "        try:\n",
    "            return graph.model_dump_json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error converting graph: {e}\")\n",
    "            return None\n",
    "\n",
    "    tasks_get_graphs = [rate_limited_extract_graph(text) for text in dataset]\n",
    "    resp = await asyncio.gather(*tasks_get_graphs)\n",
    "    df['graph'] = [safe_model_dump(graph) for graph in resp]\n",
    "\n",
    "    df.to_json('../data/interim/jokes_with_graphs.jsonl', orient='records', lines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await levels()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "122m, 56 USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_nodes(json_str):\n",
    "    try:\n",
    "        graph = json.loads(json_str)\n",
    "        return len(graph.get('nodes', []))\n",
    "    except json.JSONDecodeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_nodes'] = df['graph'].apply(count_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_nodes'].hist(bins=13, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_nodes'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out jokes with less than 3 nodes and more than 6 nodes\n",
    "df = df[(df['num_nodes'] >= 3) & (df['num_nodes'] <= 6)].reset_index(drop=True)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def keywords():\n",
    "    dataset = df['text'].tolist()\n",
    "    sem = asyncio.Semaphore(3)\n",
    "\n",
    "    async def rate_limited_extract_keywords(text: str) -> Topics:\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await extract_keywords(text, \"es\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing text: {text}\")\n",
    "                logger.error(e)\n",
    "                return []\n",
    "    \n",
    "    tasks_get_graphs = [rate_limited_extract_keywords(text) for text in dataset]\n",
    "    resp = await asyncio.gather(*tasks_get_graphs)\n",
    "\n",
    "    def safe_model_dump(topics):\n",
    "        try:\n",
    "            return topics.model_dump_json()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading topics: {e}\")\n",
    "            return None\n",
    "\n",
    "    df['keywords'] = [safe_model_dump(keywords) for keywords in resp]\n",
    "\n",
    "    df.to_json('../data/interim/jokes_with_keywords.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await keywords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_keywords(json_str):\n",
    "    try:\n",
    "        topics = json.loads(json_str)\n",
    "        return len(topics.get('keywords', []))\n",
    "    except json.JSONDecodeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_keywords'] = df['keywords'].apply(count_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_keywords'].hist(bins=10, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['num_keywords'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_keywords(keywords_str):\n",
    "    # Load the string into a dictionary\n",
    "    keywords_dict = json.loads(keywords_str)\n",
    "    keywords_list = keywords_dict['keywords']\n",
    "    return str(keywords_list).replace('\"', \"'\")\n",
    "\n",
    "# Apply the conversion to the 'keywords' column\n",
    "df['keywords'] = df['keywords'].apply(convert_keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json('../data/interim/jokes.jsonl', orient='records', lines=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['text', 'keywords']].to_json('../data/interim/jokes_fine_tuning.jsonl', orient='records', lines=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the datasets for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json('../data/interim/jokes.jsonl', orient='records', lines=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_fine_tuning_file('../data/interim/jokes.jsonl')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality = df[(df['word_count'] > 30)&(df['num_nodes'] > 3)][['text', 'keywords']].reset_index(drop=True)\n",
    "df_quality.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def refinement():\n",
    "    dataset_text = df_quality['text'].tolist()\n",
    "    dataset_keywords = df_quality['keywords'].tolist()\n",
    "\n",
    "    sem = asyncio.Semaphore(3)\n",
    "\n",
    "    async def rate_limited_refine_joke(text: str, keywords: str) -> Refinement:\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await refine_joke(text, keywords, \"es\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing text: {text}\")\n",
    "                logger.error(e)\n",
    "                return Refinement(quality=Quality.NOT_FUNNY, text=text, keywords=[])\n",
    "    \n",
    "    tasks_refine_jokes = [rate_limited_refine_joke(text, keywords) for text, keywords in zip(dataset_text, dataset_keywords)]\n",
    "    resp = await asyncio.gather(*tasks_refine_jokes)\n",
    "    df_quality['quality'] = [ref.quality.value for ref in resp]\n",
    "    df_quality['corrected_text'] = [ref.text for ref in resp]\n",
    "    df_quality['corrected_keywords'] = [ref.keywords for ref in resp]\n",
    "\n",
    "    df_quality.to_json('../data/interim/jokes_quality.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await refinement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_quality[['text', 'corrected_text', 'keywords', 'corrected_keywords', 'quality']].to_json('../data/interim/quality_jokes_to_be_cleaned.jsonl', orient='records', lines=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined = pd.read_json('../data/interim/quality_jokes_to_be_cleaned.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_refined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def rewriting():\n",
    "    dataset = df_refined['corrected_text'].tolist()\n",
    "\n",
    "    sem = asyncio.Semaphore(3)\n",
    "\n",
    "    async def rate_limited_rewrite_joke(text: str) -> Rewrite:\n",
    "        async with sem:\n",
    "            try:\n",
    "                return await rewrite_joke(text, \"es\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing text: {text}\")\n",
    "                logger.error(e)\n",
    "                return Rewrite(text=text)\n",
    "    \n",
    "    tasks_rewrite_jokes = [rate_limited_rewrite_joke(text) for text in dataset]\n",
    "    resp = await asyncio.gather(*tasks_rewrite_jokes)\n",
    "    df_refined['rewritten_text'] = [ref.rewritten_text for ref in resp]\n",
    "\n",
    "    df_refined.to_json('../data/interim/jokes_high_quality.jsonl', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await rewriting()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning = pd.read_json('../data/interim/jokes_high_quality.jsonl', orient='records', lines=True)\n",
    "df_fine_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning = df_fine_tuning[df_fine_tuning['quality'] == 'funny'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning = (df_fine_tuning[['rewritten_text', 'corrected_keywords']]\n",
    "                  .rename(columns={'rewritten_text': 'text', 'corrected_keywords': 'keywords'})\n",
    "                  .reset_index(drop=True)\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "used_keywords = set()\n",
    "\n",
    "def get_unique_keyword(keywords):\n",
    "    for keyword in keywords:\n",
    "        if keyword not in used_keywords:\n",
    "            used_keywords.add(keyword)\n",
    "            return keyword\n",
    "    return None\n",
    "\n",
    "df_fine_tuning['keyword'] = df_fine_tuning['keywords'].apply(get_unique_keyword)\n",
    "df_fine_tuning = df_fine_tuning.dropna().reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fine_tuning[['text', 'keyword']].to_json('../data/processed/jokes.jsonl', orient='records', lines=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
