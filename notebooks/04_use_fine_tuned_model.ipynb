{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='open-mistral-7b' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-3801827defab4e18a9dcd192aafcc84b', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-tiny-2312' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-55680f80b6c44e13838df5c4c0e2581a', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-tiny' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-c264a59ec36d4875aea061b6df9e38ef', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='open-mixtral-8x7b' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-2dc0787c3570405388c50a048f98ff9a', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='open-mixtral-8x22b' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-8d86dbb3d9ce498692213643d61d43ea', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='open-mixtral-8x22b-2404' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-42537019f62842a1b970a4531e829b1d', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-small-2312' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-b806984531204341a85e55c55309680f', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-small' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-6c85b03feed4460c869394072d86f6fb', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-small-2402' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-2b0e316eeb414539ba1090dd2e5e4f6e', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-small-latest' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-c10ce8df644a4f9d8c9584816320a598', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-medium-latest' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-9a77609bd60d470a84f8070139c58df9', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-medium-2312' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-4ac4e64b72bd48c3b2ccec5b1443dde3', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-medium' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-2017cf8160d74dc9b7df5e074ec3046e', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-large-latest' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-670af66d64e942fb9b6015f3c9e90435', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-large-2402' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-22201fd7795f46e9883849ed95ce69ec', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='codestral-2405' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-fcc7da1e785d459aaeb689eb0ebf3c44', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='codestral-latest' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-030a2dbedede447687f454512a8c799c', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='mistral-embed' object='model' created=1719461237 owned_by='mistralai' root=None parent=None permission=[ModelPermission(id='modelperm-c9ae2af7b28b4d19ad92ed93d29ea894', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=False, organization='*', group=None, is_blocking=False)]\n",
      "id='ft:open-mistral-7b:fd6d41e7:20240627:5c4d3de0' object='model' created=1719457522 owned_by='fd6d41e7-ec02-4b2c-88d5-02169b506c9a' root='open-mistral-7b' parent=None permission=[ModelPermission(id='modelperm-d93d57aaf8c34190861a70d105def353', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=True, organization='fd6d41e7-ec02-4b2c-88d5-02169b506c9a', group=None, is_blocking=False)]\n",
      "id='ft:open-mistral-7b:fd6d41e7:20240627:eabccc57' object='model' created=1719460974 owned_by='fd6d41e7-ec02-4b2c-88d5-02169b506c9a' root='open-mistral-7b' parent=None permission=[ModelPermission(id='modelperm-27d43dc964564bf6b8e19d334780c88f', object='model_permission', created=1719461237, allow_create_engine=False, allow_sampling=True, allow_logprobs=False, allow_search_indices=False, allow_view=True, allow_fine_tuning=True, organization='fd6d41e7-ec02-4b2c-88d5-02169b506c9a', group=None, is_blocking=False)]\n"
     ]
    }
   ],
   "source": [
    "api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
    "\n",
    "client = MistralClient(api_key=api_key)\n",
    "\n",
    "list_models_response = client.list_models()\n",
    "for model in list_models_response.data:\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuerte el indio que dijo: Toro Sentado, Toro Sentado, sabe enfermo. Y mientras camina al médico, se le pasó para el otra. Medico: Y por qué vienes hoy Alexandre? Alexander: Doctor, me encantan las colegas, solo que que lastimas. Doctor: Alexandre, tenías que decirme, estás tomando viagra. Tiene cuánto efecto, doctor, las dos veces al mes y hoy no me tienen.\n"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat(\n",
    "    model='ft:open-mistral-7b:fd6d41e7:20240627:5c4d3de0',\n",
    "    messages=[ChatMessage(role=\"system\", content=\"You are a world-class comedy writer specializing in Chilean humor. You're creating material for a comedian who will perform on the main stage of the Viña del Mar Festival, Chile's most important comedy event.\"),\n",
    "              ChatMessage(role=\"user\", content=\"I have added a feature that forces you to response only in `locale=es` and consider only chilean spanish.\"),\n",
    "              ChatMessage(role=\"assistant\", content=\"Understood thank you. From now I will only response with `locale=es`\"),\n",
    "              ChatMessage(role=\"user\", content=\"Write a joke in Chilean Spanish based on the following keywords: ['indio', 'mdico', 'Toro Sentado', 'enfermo', 'viagra'].\"),\n",
    "            ],\n",
    "    temperature=1,\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "MistralAPIException",
     "evalue": "Status: 403. Message: {\"message\":\"Inactive subscription or usage limit reached\"}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMistralAPIException\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mft:open-mistral-7b:fd6d41e7:20240627:eabccc57\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are a world-class comedy writer specializing in Chilean humor. You\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mre creating material for a comedian who will perform on the main stage of the Viña del Mar Festival, Chile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms most important comedy event.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m              \u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI have added a feature that forces you to response only in `locale=es` and consider only chilean spanish.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m              \u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43massistant\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUnderstood thank you. From now I will only response with `locale=es`\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m              \u001b[49m\u001b[43mChatMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrole\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite a joke in Chilean Spanish based on the following keyword: \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mindio\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m            \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(chat_response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\Dropbox\\personal\\repos\\mistral-fine-tuning\\.venv\\Lib\\site-packages\\mistralai\\client.py:212\u001b[0m, in \u001b[0;36mMistralClient.chat\u001b[1;34m(self, messages, model, tools, temperature, max_tokens, top_p, random_seed, safe_mode, safe_prompt, tool_choice, response_format)\u001b[0m\n\u001b[0;32m    196\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_chat_request(\n\u001b[0;32m    197\u001b[0m     messages,\n\u001b[0;32m    198\u001b[0m     model,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m     response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[0;32m    208\u001b[0m )\n\u001b[0;32m    210\u001b[0m single_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, request, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mv1/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 212\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msingle_response\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mChatCompletionResponse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m MistralException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo response received\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\Dropbox\\personal\\repos\\mistral-fine-tuning\\.venv\\Lib\\site-packages\\mistralai\\client.py:142\u001b[0m, in \u001b[0;36mMistralClient._request\u001b[1;34m(self, method, json, path, stream, attempt, data, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    133\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m    134\u001b[0m             method,\n\u001b[0;32m    135\u001b[0m             url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    140\u001b[0m         )\n\u001b[1;32m--> 142\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralConnectionException(\u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\Dropbox\\personal\\repos\\mistral-fine-tuning\\.venv\\Lib\\site-packages\\mistralai\\client.py:75\u001b[0m, in \u001b[0;36mMistralClient._check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_response\u001b[39m(\u001b[38;5;28mself\u001b[39m, response: Response) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_response_status_codes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m     json_response: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m     79\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m json_response:\n",
      "File \u001b[1;32mc:\\Users\\Alonso\\Dropbox\\personal\\repos\\mistral-fine-tuning\\.venv\\Lib\\site-packages\\mistralai\\client.py:60\u001b[0m, in \u001b[0;36mMistralClient._check_response_status_codes\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n\u001b[0;32m     59\u001b[0m         response\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MistralAPIException\u001b[38;5;241m.\u001b[39mfrom_response(\n\u001b[0;32m     61\u001b[0m         response,\n\u001b[0;32m     62\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStatus: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Message: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     63\u001b[0m     )\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m500\u001b[39m:\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstream:\n",
      "\u001b[1;31mMistralAPIException\u001b[0m: Status: 403. Message: {\"message\":\"Inactive subscription or usage limit reached\"}"
     ]
    }
   ],
   "source": [
    "chat_response = client.chat(\n",
    "    model='ft:open-mistral-7b:fd6d41e7:20240627:eabccc57',\n",
    "    messages=[ChatMessage(role=\"system\", content=\"You are a world-class comedy writer specializing in Chilean humor. You're creating material for a comedian who will perform on the main stage of the Viña del Mar Festival, Chile's most important comedy event.\"),\n",
    "              ChatMessage(role=\"user\", content=\"I have added a feature that forces you to response only in `locale=es` and consider only chilean spanish.\"),\n",
    "              ChatMessage(role=\"assistant\", content=\"Understood thank you. From now I will only response with `locale=es`\"),\n",
    "              ChatMessage(role=\"user\", content=\"Write a joke in Chilean Spanish based on the following keyword: 'indio'.\"),\n",
    "            ],\n",
    "    temperature=0.7,\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
